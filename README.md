import re
import pdfplumber
import chromadb
from chromadb.config import Settings
from chromadb.utils.embedding_functions import EmbeddingFunction
import google.generativeai as genai


# âœ… 1. è¨­å®š Gemini API é‡‘é‘°
genai.configure(api_key="YOUR_GEMINI_API_KEY")  # â† æ›¿æ›ç‚ºä½ çš„é‡‘é‘°


# âœ… 2. å®šç¾© Gemini åµŒå…¥å‡½æ•¸
class GeminiEmbeddingFunction(EmbeddingFunction):
    def __call__(self, texts):
        if isinstance(texts, str):
            texts = [texts]

        embeddings = []
        for text in texts:
            response = genai.embed_content(
                model="models/embedding-001",
                content=text,
                task_type="retrieval_document"
            )
            embeddings.append(response["embedding"])
        return embeddings


# âœ… 3. å¾ PDF æå–å…¨æ–‡
def extract_text_from_pdf(pdf_path: str) -> str:
    full_text = ""
    with pdfplumber.open(pdf_path) as pdf:
        for page in pdf.pages:
            page_text = page.extract_text()
            if page_text:
                full_text += page_text + "\n"
    return full_text.strip()


# âœ… 4. åˆ‡åˆ†ç‚ºèªæ„æ®µè½ chunks
def split_text(text: str, max_chunk_size=500, overlap=100) -> list:
    text = re.sub(r'\s+', ' ', text).strip()
    sentence_delimiters = re.compile(r'(?<=[.!?ã€‚ï¼ï¼Ÿ])\s')
    sentences = sentence_delimiters.split(text)

    chunks = []
    current_chunk = ""

    for sentence in sentences:
        if len(current_chunk) + len(sentence) + 1 <= max_chunk_size:
            current_chunk += sentence + " "
        else:
            chunks.append(current_chunk.strip())
            if overlap > 0:
                current_chunk = current_chunk[-overlap:] + sentence + " "
            else:
                current_chunk = sentence + " "

    if current_chunk:
        chunks.append(current_chunk.strip())

    return chunks


# âœ… 5. å»ºç«‹ ChromaDB ä¸¦å„²å­˜ chunks & embeddings
def create_chroma_db(documents, path="./chroma_db", name="pdf_chunks"):
    client = chromadb.Client(Settings(chroma_db_impl="duckdb+parquet", persist_directory=path))
    embedding_function = GeminiEmbeddingFunction()
    collection = client.get_or_create_collection(name=name, embedding_function=embedding_function)

    ids = [f"doc_{i}" for i in range(len(documents))]
    collection.add(documents=documents, ids=ids)

    client.persist()
    return collection


# âœ… 6. æŸ¥è©¢æœ€ç›¸é—œæ–‡å­—å€å¡Šï¼ˆå‘é‡æ¯”å°ï¼‰
def get_relevant_passage(query: str, db, n_results: int = 3) -> list:
    results = db.query(
        query_texts=[query],
        n_results=n_results
    )
    return results["documents"][0]  # å‚³å›å‰ n å€‹æ®µè½


# âœ… 7. ä¸»æµç¨‹æ•´åˆï¼ˆä¸€æ¬¡åŸ·è¡Œæ‰€æœ‰æ­¥é©Ÿï¼‰
if __name__ == "__main__":
    pdf_path = "your_file.pdf"  # â† æ›¿æ›æˆä½ çš„ PDF è·¯å¾‘
    full_text = extract_text_from_pdf(pdf_path)
    print("âœ… PDF è®€å–å®Œæˆ")

    chunks = split_text(full_text)
    print(f"âœ… åˆ†å‰²ç‚º {len(chunks)} å€‹èªæ„æ®µè½")

    collection = create_chroma_db(chunks, path="./chroma_db", name="example_pdf")
    print("âœ… Chroma å‘é‡è³‡æ–™åº«å»ºç«‹å®Œæˆ")

    # ä½¿ç”¨è€…æŸ¥è©¢ç¯„ä¾‹
    user_question = input("è«‹è¼¸å…¥å•é¡Œï¼š")
    top_chunks = get_relevant_passage(user_question, collection, n_results=3)

    print("\nğŸ” æœ€ç›¸é—œæ®µè½ï¼š")
    for i, chunk in enumerate(top_chunks):
        print(f"\n[{i+1}] {chunk}")
